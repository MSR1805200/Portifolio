{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote_notebook_id": "e39f1b48-4341-46d0-8c22-3476493f1405",
    "deepnote_execution_queue": [],
    "colab": {
      "name": "MNIST_translation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMM29HMEtrqT"
      },
      "source": [
        "# Projeto : Data Augmentation com o dataset  MNIST\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVVSDb2GuDNr"
      },
      "source": [
        "O projeto consiste em realizar o processo de translação  de imagens para observar a performance do modelo de aprendizado de máquina e comparar com o notebook exemplo que foi dado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-f52f394b-f336-41fb-a630-5371040f1261",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "39c263c7",
        "execution_millis": 187,
        "execution_start": 1611016288693,
        "deepnote_cell_type": "code",
        "id": "_-QagWrRVohr"
      },
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "\n",
        "\n",
        "# Para ajudar na reproducibilidade\n",
        "# Aqui a seed é 42, mas não há nada de especial nisso\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(fig_id, format='png', dpi=600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGSYxiiuvEy4"
      },
      "source": [
        "Abaixo está o código para importação do conjunto de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-a89a31da-0d81-4718-a9e4-25f56512f623",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "99dae9b1",
        "execution_millis": 18265,
        "execution_start": 1611016288885,
        "deepnote_cell_type": "code",
        "id": "71VMEjYeVohv"
      },
      "source": [
        "#Importando dataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-5b1bedcf-8fec-4555-80be-9cbd85e412ca",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "50f1290e",
        "execution_millis": 2,
        "execution_start": 1611016307155,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ElSxSGyVohy",
        "outputId": "2939974f-9c85-46df-ee87-6060dd3b48ca"
      },
      "source": [
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00004-26c12893-c9cb-4237-bb73-f10c5657c22a",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "4ffc51c1",
        "execution_millis": 2,
        "execution_start": 1611016307160,
        "deepnote_cell_type": "code",
        "id": "--JRD9saVohz"
      },
      "source": [
        "#funcao para plotar um digito do MNIST\n",
        "def plot_digit(data):\n",
        "    image = data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap = mpl.cm.binary,\n",
        "               interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVG1yLgYhYBE"
      },
      "source": [
        "#funcao para plotar varios digitos do MNIST\n",
        "def plot_digits(data):\n",
        "  for x in data:\n",
        "    image = x.reshape(28, 28)\n",
        "    plt.figure()\n",
        "    plt.imshow(x, cmap = mpl.cm.binary,interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UjgXHppwD5V"
      },
      "source": [
        "Abaixo está a função para translacionar os dados. Foi utilizando a biblioteca openCV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPDBY3oWWTEV"
      },
      "source": [
        "import cv2 \n",
        "\n",
        "def translate_images(features,label):\n",
        "    lista_coordenadas = [(1,0), (-1,0), (0,1), (0,-1)]\n",
        "    lista_imagens = []\n",
        "    lista_rotulo = []\n",
        "    for i in range(len(features)):\n",
        "      rotulo = label[i]\n",
        "      for c in lista_coordenadas:\n",
        "        lista_imagens.append(cv2.warpAffine(features[i].reshape(28,28), np.float32([[1, 0, c[0]], [0, 1, c[1]]]) , (28, 28)).reshape(-1))\n",
        "        lista_rotulo.append(rotulo)\n",
        "    lista_imagens = np.array(lista_imagens)\n",
        "    lista_rotulo  = np.array(lista_rotulo)\n",
        "    return lista_imagens,lista_rotulo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ZsB6ATig5O"
      },
      "source": [
        "x_train, x_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:] #dividindo os dados para treino e teste"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00007-bb5f3206-d7c4-4a88-9f1b-dbb7f862f004",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e1fc2037",
        "execution_millis": 137,
        "output_cleared": false,
        "execution_start": 1611016806961,
        "deepnote_cell_type": "code",
        "id": "f8hx41gkVoh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b91513-14fb-4546-e7eb-ed42a339ddab"
      },
      "source": [
        "x_trans,y_trans = translate_images(x_train,y_train)         #usando a translação\n",
        "\n",
        "\n",
        "\n",
        "print('Quantidade de dados com translacao:',len(x_trans))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantidade de dados com translacao: 240000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VoxMEFLjupC"
      },
      "source": [
        "shuffle_index = np.random.permutation(len(x_trans))             #embaralhando os dados\n",
        "x_train, y_train = x_trans[shuffle_index], y_trans[shuffle_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iklbpqj7RCS"
      },
      "source": [
        "Abaixo está o grid search com todos os parâmetros utilizados no notebook de exemplo. Não quero enviesar os dados colocando mais parâmetros, visto que o objetivo é comparar os erros de generalização."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngkUdn9MkaJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47f8c40-7c4d-4fad-8292-068b865159ae"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "pipe = Pipeline([\n",
        "                 ('std_scaler', StandardScaler()),\n",
        "                 ('estimator',SGDClassifier(max_iter =10,random_state = 42))\n",
        "])\n",
        "\n",
        "param_grid = [\n",
        "              {'estimator__loss' : ['hinge','log'],\n",
        "               'estimator__alpha' : [1e-4, 1e-2,1],\n",
        "              } ]\n",
        "\n",
        "grid_search = GridSearchCV(pipe,param_grid, cv =5) #obs : tive que retirar o verbose e n_jobs pois estava dando erro\n",
        "\n",
        "grid_search.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('std_scaler',\n",
              "                                        StandardScaler(copy=True,\n",
              "                                                       with_mean=True,\n",
              "                                                       with_std=True)),\n",
              "                                       ('estimator',\n",
              "                                        SGDClassifier(alpha=0.0001,\n",
              "                                                      average=False,\n",
              "                                                      class_weight=None,\n",
              "                                                      early_stopping=False,\n",
              "                                                      epsilon=0.1, eta0=0.0,\n",
              "                                                      fit_intercept=True,\n",
              "                                                      l1_ratio=0.15,\n",
              "                                                      learning_rate='optimal',\n",
              "                                                      loss='hinge', max_iter=10,\n",
              "                                                      n_iter_no_change=5,\n",
              "                                                      n_jobs=None, penalty='l2',\n",
              "                                                      power_t=0.5,\n",
              "                                                      random_state=42,\n",
              "                                                      shuffle=True, tol=0.001,\n",
              "                                                      validation_fraction=0.1,\n",
              "                                                      verbose=0,\n",
              "                                                      warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'estimator__alpha': [0.0001, 0.01, 1],\n",
              "                          'estimator__loss': ['hinge', 'log']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vacNKDXL7tH5"
      },
      "source": [
        "Observando os scores relacionados com cada combinação de parâmetros acima. Observe que os scores estão um pouco abaixo em relação ao notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljCpu8dUcyVO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "546ac45e-c2ee-40a4-dcdc-d026d089f742"
      },
      "source": [
        "results = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),\n",
        "                     pd.DataFrame(grid_search.cv_results_['std_test_score'], \n",
        "                                  columns=[\"Std\"]),\n",
        "                     pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], \n",
        "                                  columns=[\"Score\"])],axis=1)\n",
        "\n",
        "results.sort_values(\"Score\", ascending=False) #Ordenamento decrescente"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator__alpha</th>\n",
              "      <th>estimator__loss</th>\n",
              "      <th>Std</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.001735</td>\n",
              "      <td>0.872075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>log</td>\n",
              "      <td>0.002023</td>\n",
              "      <td>0.872008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.001165</td>\n",
              "      <td>0.853933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>log</td>\n",
              "      <td>0.001163</td>\n",
              "      <td>0.853200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.004709</td>\n",
              "      <td>0.810733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>log</td>\n",
              "      <td>0.004505</td>\n",
              "      <td>0.785729</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   estimator__alpha estimator__loss       Std     Score\n",
              "0            0.0001           hinge  0.001735  0.872075\n",
              "1            0.0001             log  0.002023  0.872008\n",
              "2            0.0100           hinge  0.001165  0.853933\n",
              "3            0.0100             log  0.001163  0.853200\n",
              "4            1.0000           hinge  0.004709  0.810733\n",
              "5            1.0000             log  0.004505  0.785729"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VhM89_nddl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30985e05-3f71-4958-d159-e745539b1dc2"
      },
      "source": [
        "\n",
        "modelo = Pipeline([\n",
        "                   ('std_scaler', StandardScaler()),\n",
        "                   ('estimator',SGDClassifier(max_iter=10,random_state=42))\n",
        "])\n",
        "\n",
        "\n",
        "modelo.set_params(**grid_search.best_params_)     #colocando os melhores parâmetros"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('std_scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('estimator',\n",
              "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
              "                               fit_intercept=True, l1_ratio=0.15,\n",
              "                               learning_rate='optimal', loss='hinge',\n",
              "                               max_iter=10, n_iter_no_change=5, n_jobs=None,\n",
              "                               penalty='l2', power_t=0.5, random_state=42,\n",
              "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
              "                               verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__0-ZxU3d2_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15de652c-258f-4b52-e973-dcb26c622db1"
      },
      "source": [
        "modelo.fit(x_train,y_train)    #treinando o modelo\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('std_scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('estimator',\n",
              "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
              "                               fit_intercept=True, l1_ratio=0.15,\n",
              "                               learning_rate='optimal', loss='hinge',\n",
              "                               max_iter=10, n_iter_no_change=5, n_jobs=None,\n",
              "                               penalty='l2', power_t=0.5, random_state=42,\n",
              "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
              "                               verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2BW4vryd-7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188f4f19-24cc-4735-f405-e5ab43460573"
      },
      "source": [
        "modelo.classes_ #observando as clases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwHAvHVheVan"
      },
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier #utilizando a técnica One Vs One para classificação multiclasse\n",
        "\n",
        "modelo = Pipeline([\n",
        "                   ('std_scaler',StandardScaler()),\n",
        "                   ('estimator',SGDClassifier(max_iter=1000,random_state = 42)) #aumentando o numero de iteracoes\n",
        "])\n",
        "\n",
        "modelo.set_params(**grid_search.best_params_)\n",
        "\n",
        "ovo_clf = OneVsOneClassifier(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUvDWBRUe-IC"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(ovo_clf,x_train,y_train, cv =5)  #score amostral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOsF49u1Ce8_"
      },
      "source": [
        "Abaixo observe que o score amostral diminuiu um pouco em relação ao notebook do exemplo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWBh4yXcfGv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b2b0cc-c1cd-43a6-c50a-f0d6a9c1b4d6"
      },
      "source": [
        "scores.mean()  #média do score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8997166666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLuNQ30SfuZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "721d339f-45cb-484a-809b-abd38cba2738"
      },
      "source": [
        "ovo_clf.fit(x_train, y_train) #treinando para estimar o erro de generalizacao\n",
        "\n",
        "len(ovo_clf.estimators_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Faw4X0EffyLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d50bea-8656-4e40-94c2-4ffabb6d10ee"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = ovo_clf.predict(x_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "conf_matrix #plotando a matriz de confusao"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 966,    1,    2,    1,    1,    3,    2,    2,    2,    0],\n",
              "       [   0, 1123,    4,    2,    1,    1,    3,    0,    1,    0],\n",
              "       [   7,    6,  934,   23,   18,    2,   11,    9,   21,    1],\n",
              "       [   3,    3,   13,  928,    1,   21,    3,   13,   21,    4],\n",
              "       [   1,    1,    4,    1,  938,    0,    6,    4,    1,   26],\n",
              "       [  10,    4,   10,   46,    8,  779,   12,    5,   17,    1],\n",
              "       [  13,    3,    9,    1,    5,   11,  914,    1,    1,    0],\n",
              "       [   1,    3,   17,    6,    7,    0,    1,  967,    1,   25],\n",
              "       [   7,    9,    7,   17,   12,   19,    7,    9,  880,    7],\n",
              "       [   5,    8,    1,   11,   33,    3,    0,   24,    4,  920]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWd3xM5FDls_"
      },
      "source": [
        "Observe abaixo que o score de generalização ficou um pouco maior que o score de generalização do notebook anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lA8m78RgmAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5164b926-bbcb-4c0f-e070-6db2daf92657"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred) #erro de generalização"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9349"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOF3zpUXDwXF"
      },
      "source": [
        "# Considerações finais\n",
        "\n",
        "---- \n",
        "\n",
        "Curiosamente o modelo com o processo de data augmentation mesmo não conseguindo um score amostral mais alto, conseguiu um score de generalização um pouco mais alto que o notebook de exemplo. "
      ]
    }
  ]
}